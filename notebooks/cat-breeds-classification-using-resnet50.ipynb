{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-14T17:44:24.951361Z","iopub.status.busy":"2023-05-14T17:44:24.950993Z","iopub.status.idle":"2023-05-14T17:45:35.756262Z","shell.execute_reply":"2023-05-14T17:45:35.755178Z","shell.execute_reply.started":"2023-05-14T17:44:24.951329Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","try:\n","    import torch\n","    import torchvision\n","    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n","    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n","    print(f\"torch version1: {torch.__version__}\")\n","    print(f\"torchvision version1: {torchvision.__version__}\")\n","except:\n","    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n","    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n","    import torch\n","    import torchvision\n","    print(f\"torch version: {torch.__version__}\")\n","    print(f\"torchvision version: {torchvision.__version__}\")\n","try:\n","    from torchinfo import summary\n","except:\n","    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n","    !pip install -q torchinfo\n","    from torchinfo import summary\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import random\n","import matplotlib.pyplot as plt\n","from torch import nn\n","from torchvision import transforms\n","from torchvision.models import  resnet18,ResNet18_Weights\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import ImageFolder\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","\"\"\"\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\"\"\"\n","\n","random_seed = 2023\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","random.seed(random_seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"device \",device)\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","TRAIN_DIR = \"/kaggle/input/44-cat-breed-dataset/cat dataset/train\"\n","TEST_DIR =\"/kaggle/input/44-cat-breed-dataset/cat dataset/test\"\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_dir = TRAIN_DIR\n","classes = os.listdir(data_dir)\n","classes=sorted(classes)\n","#classes.pop(-1)\n","count=0\n","for i in classes:\n","    print(\"no.items in class\",i,\"is\",len(os.listdir(data_dir+\"/\"+i)))\n","    count+=len(os.listdir(data_dir+\"/\"+i))\n","    if i[0]==\"M\":\n","        print(i)\n","print(count)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data=iter(dataset)\n","im,l=next(data)\n","show_image(im,l)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def show_image(img, label):\n","    print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n","    #cause matplotlib expects you to have the channels last insted of first like in torch\n","    plt.imshow(img.permute(1, 2, 0))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T17:52:32.608817Z","iopub.status.busy":"2023-05-14T17:52:32.608252Z","iopub.status.idle":"2023-05-14T17:52:35.596859Z","shell.execute_reply":"2023-05-14T17:52:35.595854Z","shell.execute_reply.started":"2023-05-14T17:52:32.608782Z"},"trusted":true},"outputs":[],"source":["#rom torch.datasets import ImageFolder\n","from torchvision.models import  resnet50,ResNet50_Weights\n","batch_size=64\n","train_transform =ResNet50_Weights.DEFAULT.transforms()\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize((250, 250)),\n","    transforms.ToTensor(), # ToTensor : [0, 255] -> [0, 1]\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","train_data = ImageFolder(TRAIN_DIR, train_transform)\n","test_data = ImageFolder(TEST_DIR, test_transform)\n","print(\"crying hi :)\")\n","train_loader = DataLoader(train_data,\n","                          batch_size=batch_size,\n","                          shuffle=True)\n","\n","test_loader = DataLoader(test_data, \n","                         batch_size=batch_size,\n","                         shuffle=True)\n","image_datasets={\"train\":train_data,\"test\":test_data}\n","dataloaders={\"train\":train_loader,\"test\":test_loader}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T18:36:15.740757Z","iopub.status.busy":"2023-05-14T18:36:15.740377Z","iopub.status.idle":"2023-05-14T18:36:16.272379Z","shell.execute_reply":"2023-05-14T18:36:16.271397Z","shell.execute_reply.started":"2023-05-14T18:36:15.740727Z"},"trusted":true},"outputs":[],"source":["model_conv34 = resnet50(weights=ResNet50_Weights.DEFAULT).to(device)\n","\"\"\"for param in model_conv34.parameters():\n","    param.requires_grad = False\n","\"\"\"\n","num_ftrs = model_conv34.fc.in_features\n","model_conv34.fc = nn.Linear(num_ftrs, 42)\n","\n","model_conv34 = model_conv34.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T18:36:19.511343Z","iopub.status.busy":"2023-05-14T18:36:19.510967Z","iopub.status.idle":"2023-05-14T18:36:19.519243Z","shell.execute_reply":"2023-05-14T18:36:19.518347Z","shell.execute_reply.started":"2023-05-14T18:36:19.511312Z"},"trusted":true},"outputs":[],"source":["import torch.optim as optim\n","from torch.optim import lr_scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer_conv = torch.optim.SGD(model_conv34.parameters(), lr=0.001, momentum=0.9)\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T18:36:23.421780Z","iopub.status.busy":"2023-05-14T18:36:23.421062Z","iopub.status.idle":"2023-05-14T18:36:23.436092Z","shell.execute_reply":"2023-05-14T18:36:23.435176Z","shell.execute_reply.started":"2023-05-14T18:36:23.421743Z"},"trusted":true},"outputs":[],"source":["import time\n","def train_modelv(model, criterion, optimizer, scheduler, phases,num_epochs=25 ):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch}/{num_epochs - 1}')\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in phases:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in tqdm(dataloaders[phase],desc=phase, position=0, leave=True):\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","            # deep copy the model\n","            if phase == 'test' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","            if epoch % 5==0:\n","                torch.save(model,str(epoch)+str(best_acc)+\"resnet34.pt\")\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","    print(f'Best val Acc: {best_acc:4f}')\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T18:36:26.971038Z","iopub.status.busy":"2023-05-14T18:36:26.970168Z","iopub.status.idle":"2023-05-14T19:31:34.691442Z","shell.execute_reply":"2023-05-14T19:31:34.689390Z","shell.execute_reply.started":"2023-05-14T18:36:26.971001Z"},"trusted":true},"outputs":[],"source":["import copy\n","model_conv34 = train_modelv(model_conv34, criterion, optimizer_conv,\n","                         exp_lr_scheduler,['train','test'], num_epochs=500)"]},{"cell_type":"markdown","metadata":{},"source":["I tried resnet34 without frezing and .0002 lr, for 56 and only got 30% tr_accuracy and 40% test_accur.\n","I tried resnet50 frozen and got 42% tr and 45% test for 32 epoch,lr=.001.\n","and started over with resnet50 with unfrozen layers. 9 epoch and I got 62% tr_accuracy and 56.5% test_accuracu, lr=.001, 16 epochs:64% and 57.16%, the loss is still decresing, thanks god.\n","\n","epoch 18, incresing loss for test and decresing accuracy. 64% tr_accuracy, 56.5% test_accur, \n","should I lower the lr????\n","it's epoch 22 and it keeps getting not so well, 23, decrese in tra_acc and test_acc\n","I stopped and will save the model and continue later with smaller lr.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-14T19:36:47.385991Z","iopub.status.busy":"2023-05-14T19:36:47.385622Z","iopub.status.idle":"2023-05-14T19:36:47.568158Z","shell.execute_reply":"2023-05-14T19:36:47.567199Z","shell.execute_reply.started":"2023-05-14T19:36:47.385962Z"},"trusted":true},"outputs":[],"source":["torch.save(model_conv34,\"resnet50_30epochs_65%_tr_accuracy_57%_test_accuracy.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-05-14T19:40:41.022207Z","iopub.status.busy":"2023-05-14T19:40:41.021827Z","iopub.status.idle":"2023-05-14T19:40:41.033876Z","shell.execute_reply":"2023-05-14T19:40:41.032703Z","shell.execute_reply.started":"2023-05-14T19:40:41.022176Z"},"trusted":true},"outputs":[],"source":["len(train_data.class_to_idx.keys()) #67 classes\n","train_data.class_to_idx"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
